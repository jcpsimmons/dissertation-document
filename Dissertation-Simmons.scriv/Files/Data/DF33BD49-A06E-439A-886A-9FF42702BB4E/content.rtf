{\rtf1\ansi\ansicpg1252\cocoartf1671
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;\f1\froman\fcharset0 TimesNewRomanPS-ItalicMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f0\fs24 \cf0 At this point, the OSC data import problem, and local audio routing problem were both solved and development on a usable version of 
\f1\i Spektra
\f0\i0  could formally commence. The development pipeline progressed in this manner: I would make rough paper sketches for a scene to be integrated into 
\f1\i Spektra
\f0\i0 . I would then work on the 3D art for the scene and import it as discrete game objects into the Unity engine. After creating the static scene, Micchelli and I would brainstorm mappings to be made between audio stimulus and 3D reactivity. We would A/B test these mappings in the simplest form and choose the more effective ones. These would then be neatly added to the code by Micchelli. We would perform further testing, and then fine tune the mapping values and ramp functions. \
I completed all scene sketches for 
\f1\i Spektra
\f0\i0  with Campbell\'92s Hero Cycle in mind. The user would begin inside a large structure floating in outer space. This structure was symbolic of the womb, home, stasis, conception, a buffer against the freezing cold of outer space. To further enhance this connection, I created an egg-shaped assembly inside the structure that the user could walk into and be inside, and floating semen-like beams recurrently swimming towards the egg.\
After this home/starting point scene, a lottery system was implemented in the code to select random scenes without repeating scenes until the entire aggregate had been completed. The inspiration for this development came from the serialists\'92 use of the tone row in musical compositions. This slight randomization would become a core concept of the work. I wanted to project a clear message through 
\f1\i Spektra
\f0\i0 , that of Campbell\'92s Hero Cycle, but to also allow for two user freedoms: liberty to interpret the experience according to the user\'92s own personal background and preclusions, and the freedom from having the same experience repetitively. A 360 video would have been a far better medium choice for presenting a self-similar, repeatable experience. Slight, thoughtfully constrained bits of randomness in the scene order and other facets of the code afforded numerous exploratory possibilities to the user over multiple uses of the simulation.\
Restraining the amount of randomness to an acceptable amount, i.e. not utilizing a total range such as in Schoenberg\'92s case, I was able to shape a story arc that changed slightly from viewing to viewing but would always provide the same Hero Cycle trajectory. After the womb scene, there would be a white flash to transition to the subsequent scene. This flash was to represent the \'93boundary crossing\'94. There were 4 potential scenes that could then appear in any order for the duration of the simulation: tunnel, astral landscape, Godsphere, and asteroid field. Each of these scenes featured quick dynamic animation that was both randomized and responsive to the music. The only sonic input being actively tracked in the simulation was amplitude at about 120 Hz. The audio input was run through a narrow bandpass filter at this frequency and the resultant amplitude was then scaled, inverted, and/or mapped depending on what virtual-physical parameter it was to be mapped to.\
While doing extensive testing Mark and I determined this frequency to extraordinarily significant across genres and eras of recorded music in terms of programming minimalistic form detection. The amplitude in this frequency area averaged over a two second time window was a reliable form trigger in almost all test cases involving distinct song sections. This trigger was used to force scene changes so that they coincided with switches between song sections such as the verse and chorus.\
Along the lines of subtle randomization another musical idea was integrated into the simulation. I have had a longstanding fascination with analog modular synthesizers. One of the subtle control mechanisms in that medium is the LFO, or low frequency oscillator. Micchelli was able to create a reusable, duplicatable, variable rate, oscillating sine wave function within the code. An infinite number of virtual LFOs could then be mapped to various facets of the virtual world in the simulation. As the terminology implies, these were used in order to create extremely slow changes in VR attributes such as object colors, density of objects, XYZ position of objects, et al. The slow pace of some of these oscillations, especially around the 0.25 Hz to 3 Hz range created synchronistic effects where the music and an object in the VR simulation would appear to interact, although in fact the LFO was the driver of the object, not the music. Even slower speed LFOs were experimented with in the 0.01 Hz to 0.08 Hz range. LFOs running in this range of speed produced changes in object attributes that were below detection thresholds for most users unless they were indicated to directly observe the changing attribute. These ultra-slow LFOs served to create a more atmospheric background effect to the work, only subtly noticeable on some subconscious level.\
All of these mappings worked in concert to create a dynamic user experience that portrayed different iterations of Campbell\'92s Hero Cycle as mapped to real-time audio. User reception was generally positive in the later stages of testing, with the most notable development being the improvement in form tracking for scene changes \'96 a task that before automation was simply randomized with a variable time grain, thus being noticeably unrelatable to the music. \
}